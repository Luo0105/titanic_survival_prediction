{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"é¢„å¤„ç†","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\ndef preprocess_titanic(df):\n    df = df.copy()\n\n    # ------- 1. Title æå– -------\n    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n    df['Title'] = df['Title'].replace([\n        'Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev',\n        'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    df['Title'] = df['Title'].replace({'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs'})\n\n    # ------- 2. å¡« Embarked ç¼ºå¤±ï¼ˆç”¨ä¼—æ•°å¡«ä¸´æ—¶ï¼‰+ ç¼–ç  -------\n    df['Embarked'] = df['Embarked'].fillna('S')  # ä¼—æ•°\n    le_embarked = LabelEncoder()\n    df['Embarked_code'] = le_embarked.fit_transform(df['Embarked'])\n\n    # ------- 3. å¡« Fare ç¼ºå¤±ï¼ˆç”¨ä¸­ä½æ•°ï¼‰ -------\n    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n\n    # ------- 4. ç»„åˆè¦è¡¥å€¼çš„åˆ—å¹¶åšæ ‡å‡†åŒ– -------\n    impute_cols = ['Age', 'Fare', 'Embarked_code']\n    impute_data = df[impute_cols]\n    scaler = StandardScaler()\n    impute_scaled = scaler.fit_transform(impute_data)\n\n    # ------- 5. KNN è¡¥å€¼ -------\n    imputer = KNNImputer(n_neighbors=3)\n    imputed_scaled = imputer.fit_transform(impute_scaled)\n    imputed = scaler.inverse_transform(imputed_scaled)\n\n    # ------- 6. è¿˜åŸè¡¥å€¼ç»“æœ -------\n    df['Age'] = imputed[:, 0]\n    df['Fare'] = imputed[:, 1]\n    df['Embarked'] = le_embarked.inverse_transform(imputed[:, 2].round().astype(int))\n\n    # ------- 7. è¡ç”Ÿç‰¹å¾ -------\n    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n\n    # ------- 8. ç±»åˆ«å˜é‡ç¼–ç  -------\n    le_sex = LabelEncoder()\n    le_title = LabelEncoder()\n    le_embarked_final = LabelEncoder()\n\n    df['Sex'] = le_sex.fit_transform(df['Sex'])\n    df['Title'] = le_title.fit_transform(df['Title'])\n    df['Embarked'] = le_embarked_final.fit_transform(df['Embarked'])\n\n    # ------- 9. å»é™¤ä¸ç”¨çš„åˆ— -------\n    drop_cols = ['Name', 'Ticket', 'Cabin', 'Embarked_code']\n    for col in drop_cols:\n        if col in df.columns:\n            df.drop(columns=col, inplace=True)\n\n    return df\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T12:37:07.711705Z","iopub.execute_input":"2025-05-25T12:37:07.712323Z","iopub.status.idle":"2025-05-25T12:37:07.734810Z","shell.execute_reply.started":"2025-05-25T12:37:07.712297Z","shell.execute_reply":"2025-05-25T12:37:07.733804Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# è¯»å–åŸå§‹æ•°æ®\ntrain_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\n# ä¿å­˜ PassengerId ä¾›æäº¤ç”¨\ntest_passenger_ids = test_df['PassengerId']\n\n# åˆ†ç¦»æ ‡ç­¾\ny_train = train_df['Survived']\n\n# å¤„ç†æ•°æ®\nX_train = preprocess_titanic(train_df.drop(columns=['Survived']))\nX_test = preprocess_titanic(test_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T12:37:10.868932Z","iopub.execute_input":"2025-05-25T12:37:10.869751Z","iopub.status.idle":"2025-05-25T12:37:11.009118Z","shell.execute_reply.started":"2025-05-25T12:37:10.869711Z","shell.execute_reply":"2025-05-25T12:37:11.008210Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(X_train.shape, y_train.shape)\nprint(X_test.shape)\nprint(X_train.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T12:37:13.345001Z","iopub.execute_input":"2025-05-25T12:37:13.345314Z","iopub.status.idle":"2025-05-25T12:37:13.357875Z","shell.execute_reply.started":"2025-05-25T12:37:13.345291Z","shell.execute_reply":"2025-05-25T12:37:13.356925Z"}},"outputs":[{"name":"stdout","text":"(891, 11) (891,)\n(418, 11)\n   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  Title  \\\n0            1       3    1  22.0      1      0   7.2500         2      2   \n1            2       1    0  38.0      1      0  71.2833         0      3   \n2            3       3    0  26.0      0      0   7.9250         2      1   \n3            4       1    0  35.0      1      0  53.1000         2      3   \n4            5       3    1  35.0      0      0   8.0500         2      2   \n\n   FamilySize  IsAlone  \n0           2        0  \n1           2        0  \n2           1        1  \n3           2        0  \n4           1        1  \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier, RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T12:37:15.353886Z","iopub.execute_input":"2025-05-25T12:37:15.354725Z","iopub.status.idle":"2025-05-25T12:37:15.359475Z","shell.execute_reply.started":"2025-05-25T12:37:15.354695Z","shell.execute_reply":"2025-05-25T12:37:15.358291Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# åŸºç¡€æ¨¡å‹\nxgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\nrf = RandomForestClassifier(random_state=42)\nlr = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, random_state=42))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T12:37:17.092882Z","iopub.execute_input":"2025-05-25T12:37:17.093695Z","iopub.status.idle":"2025-05-25T12:37:17.097945Z","shell.execute_reply.started":"2025-05-25T12:37:17.093668Z","shell.execute_reply":"2025-05-25T12:37:17.097165Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Stacking æ¨¡å‹ï¼šèåˆ xgb, rf, lrï¼Œæœ€ç»ˆç”¨ lr åšäºŒå±‚é¢„æµ‹å™¨\nstack_model = StackingClassifier(\n    estimators=[\n        ('xgb', xgb),\n        ('rf', rf),\n        ('lr', lr)\n    ],\n    final_estimator=LogisticRegression(max_iter=1000),\n    cv=5,\n    n_jobs=-1\n)\n\nparam_grid = {\n    'xgb__n_estimators': [100, 200],\n    'xgb__max_depth': [3, 4],\n    'xgb__learning_rate': [0.05, 0.1],\n    'rf__n_estimators': [100],\n    'rf__max_depth': [4, 6]\n}\n\ngrid_search = GridSearchCV(\n    estimator=stack_model,\n    param_grid=param_grid,\n    scoring='accuracy',\n    cv=5,\n    verbose=1,\n    n_jobs=-1\n)\n\ngrid_search.fit(X_train, y_train)\n\nprint(\"âœ… æœ€ä½³èåˆå‚æ•°ç»„åˆï¼š\", grid_search.best_params_)\nprint(\"âœ… æœ€ä½³äº¤å‰éªŒè¯å‡†ç¡®ç‡ï¼š\", grid_search.best_score_)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T12:37:19.281696Z","iopub.execute_input":"2025-05-25T12:37:19.282043Z","iopub.status.idle":"2025-05-25T12:38:14.576157Z","shell.execute_reply.started":"2025-05-25T12:37:19.282019Z","shell.execute_reply":"2025-05-25T12:38:14.575281Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 16 candidates, totalling 80 fits\nâœ… æœ€ä½³èåˆå‚æ•°ç»„åˆï¼š {'rf__max_depth': 4, 'rf__n_estimators': 100, 'xgb__learning_rate': 0.05, 'xgb__max_depth': 3, 'xgb__n_estimators': 100}\nâœ… æœ€ä½³äº¤å‰éªŒè¯å‡†ç¡®ç‡ï¼š 0.8115184232000502\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# æœ€ä¼˜æ¨¡å‹é¢„æµ‹\nbest_model = grid_search.best_estimator_\nbest_model.fit(X_train, y_train)\ny_pred = best_model.predict(X_test)\n\nsubmission = pd.DataFrame({\n    \"PassengerId\": test_passenger_ids,\n    \"Survived\": y_pred.astype(int)\n})\nsubmission.to_csv(\"submission_stacking.csv\", index=False)\nprint(\"ğŸ¯ å·²ä¿å­˜èåˆæäº¤æ–‡ä»¶ï¼šsubmission_stacking.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T12:39:56.421004Z","iopub.execute_input":"2025-05-25T12:39:56.421846Z","iopub.status.idle":"2025-05-25T12:39:58.022615Z","shell.execute_reply.started":"2025-05-25T12:39:56.421820Z","shell.execute_reply":"2025-05-25T12:39:58.021844Z"}},"outputs":[{"name":"stdout","text":"ğŸ¯ å·²ä¿å­˜èåˆæäº¤æ–‡ä»¶ï¼šsubmission_stacking.csv\n","output_type":"stream"}],"execution_count":11}]}